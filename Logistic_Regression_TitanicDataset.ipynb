{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression_TitanicDataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv2ijNk19jGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jqsjbgPnDsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Logistic_Regression:\n",
        "  def __init__(self, learning_rate, max_iter, fit_intercept=True ):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_iter = max_iter\n",
        "    self.fit_intercept = fit_intercept\n",
        "    \n",
        "  def fit(self, X, y):\n",
        "    if self.fit_intercept:\n",
        "      intercept = np.ones((X.shape[0], 1))\n",
        "      X = np.concatenate((intercept, X), axis=1)\n",
        "        \n",
        "    # weights initialization\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "        \n",
        "    for i in range(self.max_iter):\n",
        "      z = np.dot(X, self.theta)\n",
        "      h = 1 / (1 + np.exp(-z))\n",
        "      gradient = np.dot(X.T, (h - y)) /y.size\n",
        "      self.theta = self.theta - self.learning_rate * gradient\n",
        "      \n",
        "    \n",
        "  def predict(self, X):\n",
        "    if self.fit_intercept:\n",
        "      intercept = np.ones((X.shape[0], 1))\n",
        "      X = np.concatenate((intercept, X), axis=1)\n",
        "      z = np.dot(X, self.theta)\n",
        "      sig = 1 / (1 + np.exp(-z))\n",
        "    return (sig.round()).astype(int)\n",
        "\n",
        "  def fit_sklearn(X_train,Y):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    model1=LogisticRegression()\n",
        "    model1.fit(X_train,Y)\n",
        "    return model1\n",
        "\n",
        "  def predict_sklearn(X_test, model):\n",
        "    predictions_sklearn = model.predict(X_test)\n",
        "    #print(classification_report(yy_test, predictions))\n",
        "    return predictions_sklearn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWf4u8HyMyp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run():\n",
        "  train = pd.read_csv('xy_train.csv')\n",
        "  train.drop(\"Cabin\",inplace=True,axis=1)                   # lots of null values in Cabin column,so remove it\n",
        "  train.dropna(inplace=True)                                # remove all rows with null values\n",
        "  sex = pd.get_dummies(train[\"Sex\"],drop_first=True)        # create dummy variables(female, male) for Sex column. Remove the first column because one column indicates the value of the other column\n",
        "  embarked = pd.get_dummies(train[\"Embarked\"])              # create dummy variables for Embarked column\n",
        "  pclass = pd.get_dummies(train[\"Pclass\"])                  # create dummy variables for Pclass column\n",
        "\n",
        "  train = pd.concat([train,pclass,sex,embarked],axis=1)     # add dummy variables as features\n",
        "  train.drop([\"PassengerId\",\"Pclass\",\"Name\",\"Sex\",\"Ticket\",\"Embarked\"],axis=1,inplace=True)     #remove the original variables after adding dummy variables\n",
        "\n",
        "  y = train[\"Survived\"]\n",
        "  X = train.drop(\"Survived\",axis=1)\n",
        "  XX = X.values                                             # numpy array of training data points\n",
        "  yy = y.values                                             # numpy array containing 0 or 1 for each data point\n",
        "\n",
        "  X_test = pd.read_csv('x_test.csv')\n",
        "  y1 = pd.read_csv('y_test.csv')\n",
        "  X_test[\"Survived\"] = y1.drop(\"PassengerId\", axis=1)\n",
        "  X_test.drop(\"Cabin\",inplace=True,axis=1)\n",
        "  X_test.dropna(inplace=True)\n",
        "  sex = pd.get_dummies(X_test[\"Sex\"],drop_first=True)\n",
        "  embarked = pd.get_dummies(X_test[\"Embarked\"])\n",
        "  pclass = pd.get_dummies(X_test[\"Pclass\"])\n",
        "\n",
        "  X_test = pd.concat([X_test,pclass,sex,embarked],axis=1)\n",
        "  X_test.drop([\"PassengerId\",\"Pclass\",\"Name\",\"Sex\",\"Ticket\",\"Embarked\"],axis=1,inplace=True)\n",
        "\n",
        "  y_test = X_test[\"Survived\"]\n",
        "  X_test = X_test.drop(\"Survived\",axis=1)\n",
        "  XX_test = X_test.values                                   # numpy array of test data points\n",
        "  yy_test = y_test.values                                   # numpy array containing 0 or 1 for each data point\n",
        "\n",
        "\n",
        "  model = Logistic_Regression(learning_rate=0.004, max_iter=10000)\n",
        "  Logistic_Regression.fit(model, XX, yy)\n",
        "  predictions_train = Logistic_Regression.predict(model, XX)\n",
        "  print(\"Accuracy on TRAINING data using fit method : \",accuracy_score(yy, predictions_train))\n",
        "  predictions = Logistic_Regression.predict(model, XX_test)\n",
        "  print(\"Accuracy on TEST data using fit method : \",accuracy_score(yy_test, predictions))\n",
        "\n",
        "  model1 = Logistic_Regression.fit_sklearn(XX,yy)\n",
        "  predictions_sklearn_train = Logistic_Regression.predict_sklearn(XX, model1)\n",
        "  print(\"Accuracy on TRAINING data using fit_sklearn method : \",accuracy_score(yy, predictions_sklearn_train))\n",
        "  predictions_sklearn = Logistic_Regression.predict_sklearn(XX_test, model1)\n",
        "  print(\"Accuracy on TEST data using fit_sklearn method : \",accuracy_score(yy_test, predictions_sklearn))\n",
        "  \n",
        "  #print(classification_report(yy_test, predictions))\n",
        "  #print(classification_report(yy_test, predictions_sklearn))\n",
        "  #print(confusion_matrix(yy_test, predictions))\n",
        "  #print(confusion_matrix(yy_test, predictions_sklearn))\n",
        "  \n",
        "  return predictions, predictions_sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMa0lNv5PGTi",
        "colab_type": "code",
        "outputId": "000e0d85-29ec-4280-eb68-98381931dcbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "source": [
        "print(run())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on TRAINING data using fit method :  0.8047752808988764\n",
            "Accuracy on TEST data using fit method :  0.8761329305135952\n",
            "Accuracy on TRAINING data using fit_sklearn method :  0.8019662921348315\n",
            "Accuracy on TEST data using fit_sklearn method :  0.9063444108761329\n",
            "(array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
            "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
            "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
            "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
            "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
            "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
            "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
            "       0]), array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
            "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
            "       0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
            "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
            "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
            "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
            "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
            "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
            "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
            "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
            "       0]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}